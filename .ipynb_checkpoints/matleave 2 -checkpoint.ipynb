{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# FOR WEBSCRAPING \n",
    "import requests\n",
    "import requests_ftp\n",
    "import requests_cache\n",
    "import lxml\n",
    "import re\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "# PLOTTING\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# CACHE\n",
    "requests_cache.install_cache('urban_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WEBSCRAPING FAIRYGODBOSS\n",
    "url_req = requests.get(\"https://fairygodboss.com/maternity-leave-resource-center\")\n",
    "html = url_req.text\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company_info_all = []\n",
    "for i in range(80): # we know that \"end\" page on the site is 79\n",
    "    base_url = 'https://fairygodboss.com/maternity-leave-resource-center'\n",
    "    page = base_url + '?page=' + str(i)\n",
    "    url_req = requests.get(page)\n",
    "    html = url_req.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    company_info = soup.select('a[href*=\"/company-overview/\"]') #after inspecting element, this is where our info is \n",
    "    company_info_all.append(company_info)\n",
    "#company_info_all[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CREATE EMPTY LISTS FOR DATAFRAME: we need company name, industry, and 2 types of leave for each type of parent \n",
    "name = []\n",
    "industry = []\n",
    "mat_leave_pd = []\n",
    "mat_leave_unp = []\n",
    "pat_leave_pd = []\n",
    "pat_leave_unp = []\n",
    "for i in range(len(company_info_all)):\n",
    "    company_info = company_info_all[i] #extract element from list\n",
    "    for i in range(len(company_info)):\n",
    "        s = company_info[i] #extract element from sublist to get relevant information\n",
    "        #print s\n",
    "        \n",
    "        for i in range(len(s)):\n",
    "            \n",
    "            #s.find_all('li') has 6 different elements that we want, so we can use the indices 0:5 to find them\n",
    "            name.append(s.find_all('li')[0].text.strip(\"\\n\"))\n",
    "            industry.append(s.find_all('li')[1].text.split(' \\n')[1].strip())\n",
    "            mat_leave_pd.append(s.find_all('li')[2].text.split(' \\n')[1].strip())\n",
    "            mat_leave_unp.append(s.find_all('li')[3].text.split(' \\n')[1].strip())\n",
    "            pat_leave_pd.append(s.find_all('li')[4].text.split(' \\n')[1].strip())\n",
    "            pat_leave_unp.append(s.find_all('li')[5].text.split(' \\n')[1].strip())\n",
    "\n",
    "# CREATE DATAFRAME\n",
    "df = pd.DataFrame({\"name\":name, \"industry\":industry, \"maternity leave paid\":mat_leave_pd, \"maternity leave unpaid\":mat_leave_unp, \"paternity leave paid\":pat_leave_pd, \"paternity leave unpaid\":pat_leave_unp})\n",
    "\n",
    "# DROP DUPLICATES, KEEPING ONLY ONE OF EACH COMPANY\n",
    "df.drop_duplicates(subset = ['name'], keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Law Firm                                       88\n",
       "Technology: Software                           81\n",
       "Educational Services: College & Universi...    77\n",
       "Technology: Consumer Internet                  77\n",
       "Healthcare: Hospitals & Clinics                61\n",
       "Technology: B2B Tech Services                  57\n",
       "Finance: Diversified                           51\n",
       "Retail: Shoes, Accessories and Apparel         44\n",
       "Advertising                                    41\n",
       "Pharmaceutical                                 38\n",
       "Consulting Services                            36\n",
       "Finance: Asset Management                      33\n",
       "Technology: Manufacturing                      25\n",
       "Hospitality: Restaurants                       24\n",
       "Healthcare: Medical Devices                    23\n",
       "Media: Diversified                             20\n",
       "Consumer Packaged Goods: Packaged Foods        20\n",
       "Telecommunications                             19\n",
       "Natural Resources: Oil & Gas                   19\n",
       "Insurance: Property & Casualty                 19\n",
       "Retail: Supermarket Company                    18\n",
       "Healthcare: Services                           14\n",
       "Government: State                              14\n",
       "Business Services: Staffing & Outsourcin...    14\n",
       "Finance: Personal & Commercial Banking         13\n",
       "Insurance: Health                              13\n",
       "Government: Federal                            13\n",
       "Media: News                                    12\n",
       "Retail: Department Store                       12\n",
       "Accounting Services                            11\n",
       "                                               ..\n",
       "Healthcare: Laboratory Testing                  2\n",
       "Finance: Venture Capital                        1\n",
       "Textiles                                        1\n",
       "Nonprofit: Libraries                            1\n",
       "Information Services: Legal                     1\n",
       "Services: Salons & Spas                         1\n",
       "Sporting Goods                                  1\n",
       "Healthcare: Telemedicine                        1\n",
       "Nonprofit: Science & Technology                 1\n",
       "Maritime                                        1\n",
       "Real Estate: Brokers                            1\n",
       "Educational Services: Preschool                 1\n",
       "Nonprofit: Religious                            1\n",
       "Real Estate: Other                              1\n",
       "Nonprofit: Legal                                1\n",
       "Fine Art Auctions                               1\n",
       "Business Services: Business Events              1\n",
       "Nonprofit: Professional Development             1\n",
       "Nonprofit: Trade Organization                   1\n",
       "Natural Resources: Agrochemical                 1\n",
       "Finance: Credit Unions                          1\n",
       "Retail: Books                                   1\n",
       "Retail: Stationary & Office Supplies            1\n",
       "Nonprofit: Interest Group                       1\n",
       "Nonprofit: Youth Development                    1\n",
       "Insurance: Reinsurance                          1\n",
       "Nonprofit: Animal Welfare                       1\n",
       "Services: Daycare                               1\n",
       "Nonprofit: Political Organization               1\n",
       "Healthcare: Behavioral                          1\n",
       "Name: industry, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df #we could poentially take the mean of each paid matleave and patleave and bargraph it according to each industry. hell yeah\n",
    "df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df` is the dataframe I want to work with. The relevant information given by this dataset is industry, company name, and maternity and paternity leave (paid and unpaid for both). For the purposes of our analysis, we are going to focus on paid parental leave and see how this plays a role in social trends. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, as a summary, we want to determine how many types of industries there are in our dataframe and how many companies there are per industry. We can do this by just counting the unique values. A couple issues with this are that there are no duplicate industries at all, from a pandas perspective. When we look at it visually, we see that there are \"groups\" of industries such a \"Technology: Security\" and \"Technology: Software\", etc. First, we were going to create a column called `df['sector']` with industry names up till the \":\" (using regex), but we decided it would be a better idea to just make the `sector` column by extracting the first word of every industry string. \n",
    "\n",
    "We want to look at only the top 10 industries in terms of company counts, to hopefully have a larger sample per industry (for example, industries such as \"Arts & Entertainment\" only have one company listed on fairygodboss, and in this case, although the samples are still small, these are all greater than 5, which is the best we're going to get with the information we have. \n",
    "\n",
    "From this subset, we have the most information about the nonprofit sector. We are interested in focusing in on the four following sectors: nonprofit technology, business, and government. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numcompanies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nonprofit:</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retail:</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare:</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natural</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology:</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrial:</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finance:</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Educational</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Government:</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             numcompanies\n",
       "Nonprofit:             22\n",
       "Retail:                14\n",
       "Healthcare:            11\n",
       "Natural                11\n",
       "Technology:             9\n",
       "Industrial:             9\n",
       "Business                7\n",
       "Finance:                7\n",
       "Educational             6\n",
       "Government:             6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry']\n",
    "df['numcompanies'] = [s.split(\" \")[0] for s in df['industry']]\n",
    "#df['sector'].value_counts()[:10]\n",
    "sectordf = pd.DataFrame(df['numcompanies'].value_counts()[:10]) #dont have to do each sector; just compare nonprofit, tech, and business, and government \n",
    "sectordf\n",
    "#differences column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the information about the companies within these 10 industries, and determine the parental leave information. Since we're interested primarily in nonprofit, tech, business, and government, we'll look at those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-217c9d14d3f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#company %in% nonprofit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sector'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msector\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Niveditha_2\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Niveditha_2\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Niveditha_2\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Niveditha_2\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Niveditha_2\\Anaconda2\\lib\\site-packages\\pandas\\indexes\\base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sector'"
     ]
    }
   ],
   "source": [
    "#company %in% nonprofit \n",
    "df.head()\n",
    "if df['sector'] in sector: \n",
    "    print true"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
